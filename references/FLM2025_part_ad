‹† (x)z
â‹†
â„“Î¸ (w, Î¸ (x)) = âˆ’
âŠ—z
t âˆ’ Î¶1â‹† (x) âˆ’ Î¶2â‹† (x)z

and

â„“Î¸Î¸ (w, Î¸ â‹† (x)) = I2 âŠ— z1 z1â€² .

Therefore Î›(x) = I2 âŠ— Î›Z (x), where Î›Z (x) = E[z1 z1â€² | X = x].
As before, our score is not the only possibility for estimation and inference IV models.
Our approach aims for ease of use and transparency, both by sticking to the two stage least
squares and by the structural compatibility of deep learning. Restricting to homogeneous
effects, Chernozhukov et al. (2018a) study partially linear IV models and study three different
possibly orthogonal scores, each requiring different functions in the first step and in the
correction term. The same could be done in our unrestricted model. As in partially linear
models, if any parameters are constant this can be enforced in the architecture. It is not
obvious which approach is best.

66

