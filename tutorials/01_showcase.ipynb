{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "### 5.4 Randomization Mode: Compute Λ Instead of Estimating\n\nFor **randomized experiments** where T is independent of X and has known distribution $F_T$:\n\n- **Regime A**: Λ(x) can be **computed** via Monte Carlo integration\n- Faster, more stable (no Λ network to train)\n- Uses **2-way cross-fitting** (not 3-way)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Demonstrate randomization mode with ComputeLambda\n# In RCTs where T ~ N(0,1) is independent of X, we can COMPUTE Lambda\n\nprint(\"Running inference() with randomization mode...\")\nprint(\"(T is randomized ~ N(0,1), independent of X)\")\n\nresult_rct = inference(\n    Y=Y_logit, T=T_logit, X=X_logit.reshape(-1, 1),\n    model='logit',\n    target='beta',\n    is_randomized=True,\n    treatment_dist=Normal(mean=0.0, std=1.0),  # Known treatment distribution\n    n_folds=N_FOLDS,\n    epochs=EPOCHS,\n    verbose=True  # Shows \"Regime A\" detection\n)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"RANDOMIZATION MODE (REGIME A) RESULTS\")\nprint(\"=\"*60)\nprint(f\"True mu* = {MU_TRUE_LOGIT}\")\nprint(f\"Estimate: {result_rct.mu_hat:.4f}\")\nprint(f\"SE: {result_rct.se:.4f}\")\nprint(f\"95% CI: [{result_rct.ci_lower:.4f}, {result_rct.ci_upper:.4f}]\")\nprint(f\"Covers true: {result_rct.ci_lower <= MU_TRUE_LOGIT <= result_rct.ci_upper}\")\nprint(f\"\\nDiagnostics:\")\nprint(f\"  Regime: {result_rct.diagnostics.get('regime', 'N/A')}\")\nprint(f\"  Lambda method: {result_rct.diagnostics.get('lambda_method', 'N/A')}\")\nprint(\"=\"*60)\nprint(\"\\nBenefits of Regime A:\")\nprint(\"  - Lambda computed via MC integration (not estimated)\")\nprint(\"  - 2-way cross-fitting (not 3-way)\")\nprint(\"  - More stable, often faster\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import torch\n\n# Define custom target: Average Prediction at t=0\ndef prediction_target(x, theta, t_tilde):\n    \"\"\"H = sigma(alpha + beta * t_tilde)\"\"\"\n    alpha = theta[0]\n    beta = theta[1]\n    logits = alpha + beta * t_tilde\n    return torch.sigmoid(logits)\n\nprint(\"Running inference() with custom target (Average Prediction at T=0)...\")\nresult_custom = inference(\n    Y=Y_logit, T=T_logit, X=X_logit.reshape(-1, 1),\n    model='logit',\n    target_fn=prediction_target,\n    t_tilde=0.0,\n    n_folds=N_FOLDS,\n    epochs=EPOCHS,\n    verbose=False\n)\n\n# Oracle: E[sigma(alpha)]\noracle_pred = expit(alpha_logit).mean()\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"CUSTOM TARGET: Average Prediction at T=0\")\nprint(\"=\"*60)\nprint(f\"Oracle E[σ(α)]: {oracle_pred:.4f}\")\nprint(f\"inference():    {result_custom.mu_hat:.4f}\")\nprint(f\"SE: {result_custom.se:.4f}\")\nprint(f\"95% CI: [{result_custom.ci_lower:.4f}, {result_custom.ci_upper:.4f}]\")\nprint(f\"Covers oracle: {result_custom.ci_lower <= oracle_pred <= result_custom.ci_upper}\")\nprint(\"=\"*60)\nprint(f\"\\nNote: The Jacobian of H w.r.t. θ was computed via autodiff!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 5.3 Custom Target Functions\n\nYou can define any target function `h(x, theta, t_tilde)` and the package will compute its Jacobian via autodiff.\n\nExample: **Average Prediction** at $\\tilde{t}=0$\n\n$$H = \\mathbb{E}[\\sigma(\\alpha(X) + \\beta(X) \\cdot 0)] = \\mathbb{E}[\\sigma(\\alpha(X))]$$",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Compute AME using inference() with target='ame'\nprint(\"Running inference() with target='ame'...\")\nresult_ame = inference(\n    Y=Y_logit, T=T_logit, X=X_logit.reshape(-1, 1),\n    model='logit',\n    target='ame',\n    t_tilde=0.0,  # Evaluate AME at T=0\n    n_folds=N_FOLDS,\n    epochs=EPOCHS,\n    verbose=False\n)\n\n# Compute oracle AME using our data\n# AME = E[p(1-p) * beta] where p = sigma(alpha) at t=0\np_at_0 = expit(alpha_logit)  # p(Y=1|T=0)\noracle_ame = (p_at_0 * (1 - p_at_0) * beta_logit).mean()\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"AVERAGE MARGINAL EFFECT (AME) RESULTS\")\nprint(\"=\"*60)\nprint(f\"Oracle AME (true): {oracle_ame:.4f}\")\nprint(f\"inference() AME:   {result_ame.mu_hat:.4f}\")\nprint(f\"SE: {result_ame.se:.4f}\")\nprint(f\"95% CI: [{result_ame.ci_lower:.4f}, {result_ame.ci_upper:.4f}]\")\nprint(f\"Covers oracle: {result_ame.ci_lower <= oracle_ame <= result_ame.ci_upper}\")\nprint(\"=\"*60)\nprint(f\"\\nNote: AME ≈ 0.25 × 0.5 = 0.125 (since p(1-p) ≈ 0.25 at p≈0.5)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 5.2 Flexible Targets: Average Marginal Effect (AME)\n\nFor logit models, the **Average Marginal Effect** captures the effect on probability (not log-odds):\n\n$$\\text{AME} = \\mathbb{E}[p(1-p) \\cdot \\beta(X)]$$\n\nwhere $p = \\sigma(\\alpha(X) + \\beta(X) \\cdot \\tilde{t})$ is evaluated at the target treatment level $\\tilde{t}=0$.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Compare structural_dml() vs inference() on logit\nprint(\"Running structural_dml() (legacy API)...\")\nresult_old = structural_dml(\n    Y=Y_logit, T=T_logit, X=X_logit.reshape(-1, 1),\n    family='logit',\n    n_folds=N_FOLDS,\n    epochs=EPOCHS,\n    # lambda_method='ridge' is default (96% coverage)\n    verbose=False\n)\n\nprint(\"Running inference() (new API)...\")\nresult_new = inference(\n    Y=Y_logit, T=T_logit, X=X_logit.reshape(-1, 1),\n    model='logit',\n    target='beta',\n    n_folds=N_FOLDS,\n    epochs=EPOCHS,\n    verbose=True  # Show regime detection\n)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"COMPARISON: structural_dml() vs inference()\")\nprint(\"=\"*60)\nprint(f\"True mu* = {MU_TRUE_LOGIT}\")\nprint(f\"\\n{'API':<20} {'Estimate':>12} {'SE':>10} {'CI_lo':>10} {'CI_hi':>10}\")\nprint(\"-\"*60)\nprint(f\"{'structural_dml()':<20} {result_old.mu_hat:>12.4f} {result_old.se:>10.4f} {result_old.ci_lower:>10.4f} {result_old.ci_upper:>10.4f}\")\nprint(f\"{'inference()':<20} {result_new.mu_hat:>12.4f} {result_new.se:>10.4f} {result_new.ci_lower:>10.4f} {result_new.ci_upper:>10.4f}\")\nprint(\"=\"*60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 5.1 Basic Usage: `inference()` vs `structural_dml()`\n\nBoth APIs should produce similar results for `target='beta'`:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Import the new inference API\nfrom deep_inference import inference\nfrom deep_inference.lambda_.compute import Normal\n\n# Re-generate Logit data for comparison\nnp.random.seed(SEED)\nX_logit = np.random.normal(0, 1, N)\nT_logit = np.random.normal(0, 1, N)\nalpha_logit = 0.0 + 0.3 * X_logit\nbeta_logit = 0.5 + 0.2 * X_logit\nprob_logit = expit(alpha_logit + beta_logit * T_logit)\nY_logit = np.random.binomial(1, prob_logit).astype(float)\n\nprint(\"New inference() API loaded!\")\nprint(f\"Using same Logit DGP: True mu* = {MU_TRUE_LOGIT}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Inference: Package Showcase\n",
    "\n",
    "This tutorial demonstrates the `deep_inference` package for structural deep learning with valid inference.\n",
    "\n",
    "**What this package does:**\n",
    "- Estimates heterogeneous structural parameters θ(x) using neural networks\n",
    "- Provides valid 95% confidence intervals via influence functions\n",
    "- Implements Farrell, Liang, Misra (2021, 2025) framework\n",
    "\n",
    "**What we'll show:**\n",
    "- 4 model families: Linear, Logit, Gaussian, Poisson\n",
    "- For each: compare NN estimates vs Oracle (closed-form)\n",
    "- Demonstrate that influence functions correct for regularization bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.special import expit\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add package to path\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from deep_inference import structural_dml\n",
    "\n",
    "print(\"Package loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common settings\n",
    "N = 2000        # Sample size\n",
    "SEED = 42       # Random seed\n",
    "N_FOLDS = 30    # Cross-fitting folds\n",
    "EPOCHS = 100    # Training epochs\n",
    "\n",
    "def print_comparison(oracle_results, nn_results, mu_true, title):\n",
    "    \"\"\"Print side-by-side comparison table.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{title}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"True μ* = {mu_true:.6f}\")\n",
    "    print(f\"\\n{'Method':<20} {'Estimate':>12} {'SE':>10} {'CI_lo':>10} {'CI_hi':>10} {'Covers':>8}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for name, res in [*oracle_results.items(), *nn_results.items()]:\n",
    "        covers = res['ci_lo'] <= mu_true <= res['ci_hi']\n",
    "        print(f\"{name:<20} {res['estimate']:>12.6f} {res['se']:>10.6f} {res['ci_lo']:>10.4f} {res['ci_hi']:>10.4f} {'YES' if covers else 'NO':>8}\")\n",
    "    \n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Linear Family\n",
    "\n",
    "**Model:** $Y = \\alpha(X) + \\beta(X) \\cdot T + \\varepsilon$\n",
    "\n",
    "**Target:** $\\mu^* = \\mathbb{E}[\\beta(X)]$ (Average Treatment Effect)\n",
    "\n",
    "**Oracle:** OLS with interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LINEAR FAMILY ===\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"# LINEAR FAMILY\")\n",
    "print(\"#\"*70)\n",
    "\n",
    "# DGP Parameters\n",
    "A0, A1 = 1.0, 0.3    # alpha(x) = A0 + A1*x\n",
    "B0, B1 = 0.5, 0.2    # beta(x) = B0 + B1*x\n",
    "SIGMA = 1.0          # noise std\n",
    "\n",
    "# True target: E[beta(X)] = B0 (since E[X] = 0)\n",
    "MU_TRUE_LINEAR = B0\n",
    "\n",
    "# Generate data\n",
    "np.random.seed(SEED)\n",
    "X = np.random.normal(0, 1, N)\n",
    "T = np.random.normal(0, 1, N)\n",
    "alpha_true = A0 + A1 * X\n",
    "beta_true = B0 + B1 * X\n",
    "Y = alpha_true + beta_true * T + np.random.normal(0, SIGMA, N)\n",
    "\n",
    "print(f\"\\nDGP:\")\n",
    "print(f\"  alpha*(x) = {A0} + {A1}*x\")\n",
    "print(f\"  beta*(x) = {B0} + {B1}*x\")\n",
    "print(f\"  Y = alpha(X) + beta(X)*T + eps, eps ~ N(0, {SIGMA})\")\n",
    "print(f\"  True mu* = E[beta(X)] = {MU_TRUE_LINEAR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oracle: OLS with interaction\n",
    "# Y = b0 + b1*X + b2*T + b3*X*T\n",
    "# beta(x) = b2 + b3*x, so E[beta(X)] = b2 (since E[X]=0)\n",
    "\n",
    "X_design = np.column_stack([np.ones(N), X, T, X*T])\n",
    "ols = sm.OLS(Y, X_design).fit()\n",
    "\n",
    "b2, b3 = ols.params[2], ols.params[3]\n",
    "mu_oracle = b2 + b3 * X.mean()  # approx b2 since E[X] approx 0\n",
    "\n",
    "# Naive SE: just SE of b2\n",
    "se_naive = ols.bse[2]\n",
    "\n",
    "# Delta method SE: accounts for variance in X_bar\n",
    "cov = ols.cov_params()\n",
    "se_delta = np.sqrt(cov[2,2] + X.mean()**2 * cov[3,3] + 2*X.mean()*cov[2,3])\n",
    "\n",
    "oracle_linear = {\n",
    "    'Oracle (Naive SE)': {\n",
    "        'estimate': mu_oracle,\n",
    "        'se': se_naive,\n",
    "        'ci_lo': mu_oracle - 1.96*se_naive,\n",
    "        'ci_hi': mu_oracle + 1.96*se_naive\n",
    "    },\n",
    "    'Oracle (Delta SE)': {\n",
    "        'estimate': mu_oracle,\n",
    "        'se': se_delta,\n",
    "        'ci_lo': mu_oracle - 1.96*se_delta,\n",
    "        'ci_hi': mu_oracle + 1.96*se_delta\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Oracle OLS coefficients:\")\n",
    "print(f\"  b2 (T coef) = {b2:.6f}\")\n",
    "print(f\"  b3 (X*T coef) = {b3:.6f}\")\n",
    "print(f\"  mu_oracle = {mu_oracle:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN: structural_dml with linear family\n",
    "result_linear = structural_dml(\n",
    "    Y=Y, T=T, X=X.reshape(-1, 1),\n",
    "    family='linear',\n",
    "    n_folds=N_FOLDS,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "nn_linear = {\n",
    "    'NN (Naive)': {\n",
    "        'estimate': result_linear.mu_naive,\n",
    "        'se': result_linear.theta_hat[:, 1].std() / np.sqrt(N),\n",
    "        'ci_lo': result_linear.mu_naive - 1.96 * result_linear.theta_hat[:, 1].std() / np.sqrt(N),\n",
    "        'ci_hi': result_linear.mu_naive + 1.96 * result_linear.theta_hat[:, 1].std() / np.sqrt(N)\n",
    "    },\n",
    "    'NN (IF Corrected)': {\n",
    "        'estimate': result_linear.mu_hat,\n",
    "        'se': result_linear.se,\n",
    "        'ci_lo': result_linear.ci_lower,\n",
    "        'ci_hi': result_linear.ci_upper\n",
    "    }\n",
    "}\n",
    "\n",
    "print_comparison(oracle_linear, nn_linear, MU_TRUE_LINEAR, \"LINEAR FAMILY RESULTS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Logit Family\n",
    "\n",
    "**Model:** $P(Y=1|X,T) = \\sigma(\\alpha(X) + \\beta(X) \\cdot T)$\n",
    "\n",
    "**Target:** $\\mu^* = \\mathbb{E}[\\beta(X)]$ (Average log-odds treatment effect)\n",
    "\n",
    "**Oracle:** Logistic regression with interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOGIT FAMILY ===\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"# LOGIT FAMILY\")\n",
    "print(\"#\"*70)\n",
    "\n",
    "# DGP Parameters\n",
    "A0, A1 = 0.0, 0.3    # alpha(x) = A0 + A1*x\n",
    "B0, B1 = 0.5, 0.2    # beta(x) = B0 + B1*x\n",
    "\n",
    "# True target: E[beta(X)] = B0 (since E[X] = 0)\n",
    "MU_TRUE_LOGIT = B0\n",
    "\n",
    "# Generate data\n",
    "np.random.seed(SEED)\n",
    "X = np.random.normal(0, 1, N)\n",
    "T = np.random.normal(0, 1, N)\n",
    "alpha_true = A0 + A1 * X\n",
    "beta_true = B0 + B1 * X\n",
    "prob = expit(alpha_true + beta_true * T)\n",
    "Y = np.random.binomial(1, prob).astype(float)\n",
    "\n",
    "print(f\"\\nDGP:\")\n",
    "print(f\"  alpha*(x) = {A0} + {A1}*x\")\n",
    "print(f\"  beta*(x) = {B0} + {B1}*x\")\n",
    "print(f\"  P(Y=1|X,T) = sigmoid(alpha(X) + beta(X)*T)\")\n",
    "print(f\"  True mu* = E[beta(X)] = {MU_TRUE_LOGIT}\")\n",
    "print(f\"  Mean(Y) = {Y.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oracle: Logistic regression with interaction\n",
    "X_design = np.column_stack([np.ones(N), X, T, X*T])\n",
    "logit = sm.Logit(Y, X_design).fit(disp=0)\n",
    "\n",
    "b2, b3 = logit.params[2], logit.params[3]\n",
    "mu_oracle = b2 + b3 * X.mean()\n",
    "\n",
    "se_naive = logit.bse[2]\n",
    "cov = logit.cov_params()\n",
    "se_delta = np.sqrt(cov[2,2] + X.mean()**2 * cov[3,3] + 2*X.mean()*cov[2,3])\n",
    "\n",
    "oracle_logit = {\n",
    "    'Oracle (Naive SE)': {\n",
    "        'estimate': mu_oracle,\n",
    "        'se': se_naive,\n",
    "        'ci_lo': mu_oracle - 1.96*se_naive,\n",
    "        'ci_hi': mu_oracle + 1.96*se_naive\n",
    "    },\n",
    "    'Oracle (Delta SE)': {\n",
    "        'estimate': mu_oracle,\n",
    "        'se': se_delta,\n",
    "        'ci_lo': mu_oracle - 1.96*se_delta,\n",
    "        'ci_hi': mu_oracle + 1.96*se_delta\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Oracle Logit coefficients:\")\n",
    "print(f\"  b2 (T coef) = {b2:.6f}\")\n",
    "print(f\"  b3 (X*T coef) = {b3:.6f}\")\n",
    "print(f\"  mu_oracle = {mu_oracle:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# NN: structural_dml with logit family\nresult_logit = structural_dml(\n    Y=Y, T=T, X=X.reshape(-1, 1),\n    family='logit',\n    n_folds=N_FOLDS,\n    epochs=EPOCHS,\n    # lambda_method='ridge' is default (96% coverage)\n    verbose=False\n)\n\nnn_logit = {\n    'NN (Naive)': {\n        'estimate': result_logit.mu_naive,\n        'se': result_logit.theta_hat[:, 1].std() / np.sqrt(N),\n        'ci_lo': result_logit.mu_naive - 1.96 * result_logit.theta_hat[:, 1].std() / np.sqrt(N),\n        'ci_hi': result_logit.mu_naive + 1.96 * result_logit.theta_hat[:, 1].std() / np.sqrt(N)\n    },\n    'NN (IF Corrected)': {\n        'estimate': result_logit.mu_hat,\n        'se': result_logit.se,\n        'ci_lo': result_logit.ci_lower,\n        'ci_hi': result_logit.ci_upper\n    }\n}\n\nprint_comparison(oracle_logit, nn_logit, MU_TRUE_LOGIT, \"LOGIT FAMILY RESULTS\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Gaussian Family\n",
    "\n",
    "**Model:** $Y \\sim N(\\alpha(X) + \\beta(X) \\cdot T, \\sigma^2(X))$\n",
    "\n",
    "**Target:** $\\mu^* = \\mathbb{E}[\\beta(X)]$\n",
    "\n",
    "**Note:** Gaussian family uses identity link for mean (like Linear) but estimates heterogeneous variance sigma(x) via MLE. theta_dim = 3: (alpha, beta, gamma) where sigma = exp(gamma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GAUSSIAN FAMILY ===\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"# GAUSSIAN FAMILY\")\n",
    "print(\"#\"*70)\n",
    "\n",
    "# DGP Parameters (identity link for mean)\n",
    "A0, A1 = 2.0, 0.3    # alpha(x) = A0 + A1*x\n",
    "B0, B1 = 0.5, 0.2    # beta(x) = B0 + B1*x\n",
    "SIGMA = 1.0          # noise std (homogeneous for simplicity)\n",
    "\n",
    "# True target: E[beta(X)] = B0\n",
    "MU_TRUE_GAUSSIAN = B0\n",
    "\n",
    "# Generate data\n",
    "np.random.seed(SEED)\n",
    "X = np.random.normal(0, 1, N)\n",
    "T = np.random.normal(0, 1, N)\n",
    "alpha_true = A0 + A1 * X\n",
    "beta_true = B0 + B1 * X\n",
    "mu_y = alpha_true + beta_true * T  # Identity link!\n",
    "Y = mu_y + np.random.normal(0, SIGMA, N)\n",
    "\n",
    "print(f\"\\nDGP:\")\n",
    "print(f\"  alpha*(x) = {A0} + {A1}*x\")\n",
    "print(f\"  beta*(x) = {B0} + {B1}*x\")\n",
    "print(f\"  E[Y|X,T] = alpha(X) + beta(X)*T  (identity link)\")\n",
    "print(f\"  Y ~ N(mu, sigma^2), sigma = {SIGMA}\")\n",
    "print(f\"  True mu* = E[beta(X)] = {MU_TRUE_GAUSSIAN}\")\n",
    "print(f\"  Mean(Y) = {Y.mean():.3f}, Std(Y) = {Y.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oracle: OLS with interaction (same as linear since identity link)\n",
    "X_design = np.column_stack([np.ones(N), X, T, X*T])\n",
    "ols = sm.OLS(Y, X_design).fit()\n",
    "\n",
    "b2, b3 = ols.params[2], ols.params[3]\n",
    "mu_oracle = b2 + b3 * X.mean()\n",
    "\n",
    "se_naive = ols.bse[2]\n",
    "cov = ols.cov_params()\n",
    "se_delta = np.sqrt(cov[2,2] + X.mean()**2 * cov[3,3] + 2*X.mean()*cov[2,3])\n",
    "\n",
    "oracle_gaussian = {\n",
    "    'Oracle (Naive SE)': {\n",
    "        'estimate': mu_oracle,\n",
    "        'se': se_naive,\n",
    "        'ci_lo': mu_oracle - 1.96*se_naive,\n",
    "        'ci_hi': mu_oracle + 1.96*se_naive\n",
    "    },\n",
    "    'Oracle (Delta SE)': {\n",
    "        'estimate': mu_oracle,\n",
    "        'se': se_delta,\n",
    "        'ci_lo': mu_oracle - 1.96*se_delta,\n",
    "        'ci_hi': mu_oracle + 1.96*se_delta\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Oracle OLS coefficients:\")\n",
    "print(f\"  b2 (T coef) = {b2:.6f}\")\n",
    "print(f\"  b3 (X*T coef) = {b3:.6f}\")\n",
    "print(f\"  mu_oracle = {mu_oracle:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# NN: structural_dml with gaussian family\n# Note: Gaussian estimates sigma(x) via MLE, so theta_dim=3\nresult_gaussian = structural_dml(\n    Y=Y, T=T, X=X.reshape(-1, 1),\n    family='gaussian',\n    n_folds=N_FOLDS,\n    epochs=EPOCHS,\n    # lambda_method='ridge' is default\n    verbose=False\n)\n\nnn_gaussian = {\n    'NN (Naive)': {\n        'estimate': result_gaussian.mu_naive,\n        'se': result_gaussian.theta_hat[:, 1].std() / np.sqrt(N),\n        'ci_lo': result_gaussian.mu_naive - 1.96 * result_gaussian.theta_hat[:, 1].std() / np.sqrt(N),\n        'ci_hi': result_gaussian.mu_naive + 1.96 * result_gaussian.theta_hat[:, 1].std() / np.sqrt(N)\n    },\n    'NN (IF Corrected)': {\n        'estimate': result_gaussian.mu_hat,\n        'se': result_gaussian.se,\n        'ci_lo': result_gaussian.ci_lower,\n        'ci_hi': result_gaussian.ci_upper\n    }\n}\n\nprint_comparison(oracle_gaussian, nn_gaussian, MU_TRUE_GAUSSIAN, \"GAUSSIAN FAMILY RESULTS\")\n\n# Also show estimated sigma\nsigma_hat = np.exp(result_gaussian.theta_hat[:, 2]).mean()\nprint(f\"\\nEstimated sigma: {sigma_hat:.4f} (true: {SIGMA})\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Poisson Family\n",
    "\n",
    "**Model:** $Y \\sim \\text{Poisson}(\\exp(\\alpha(X) + \\beta(X) \\cdot T))$\n",
    "\n",
    "**Target:** $\\mu^* = \\mathbb{E}[\\beta(X)]$ (Average log-rate treatment effect)\n",
    "\n",
    "**Oracle:** Poisson regression with interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === POISSON FAMILY ===\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"# POISSON FAMILY\")\n",
    "print(\"#\"*70)\n",
    "\n",
    "# DGP Parameters\n",
    "A0, A1 = 1.5, 0.2    # alpha(x) = A0 + A1*x\n",
    "B0, B1 = 0.3, 0.1    # beta(x) = B0 + B1*x\n",
    "\n",
    "# True target: E[beta(X)] = B0\n",
    "MU_TRUE_POISSON = B0\n",
    "\n",
    "# Generate data\n",
    "np.random.seed(SEED)\n",
    "X = np.random.normal(0, 1, N)\n",
    "T = np.random.normal(0, 0.5, N)  # Smaller T variance to avoid extreme counts\n",
    "alpha_true = A0 + A1 * X\n",
    "beta_true = B0 + B1 * X\n",
    "rate = np.exp(alpha_true + beta_true * T)\n",
    "Y = np.random.poisson(rate).astype(float)\n",
    "\n",
    "print(f\"\\nDGP:\")\n",
    "print(f\"  alpha*(x) = {A0} + {A1}*x\")\n",
    "print(f\"  beta*(x) = {B0} + {B1}*x\")\n",
    "print(f\"  Y ~ Poisson(exp(alpha(X) + beta(X)*T))\")\n",
    "print(f\"  True mu* = E[beta(X)] = {MU_TRUE_POISSON}\")\n",
    "print(f\"  Mean(Y) = {Y.mean():.3f}, Var(Y) = {Y.var():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oracle: Poisson regression with interaction\n",
    "X_design = np.column_stack([np.ones(N), X, T, X*T])\n",
    "poisson = sm.GLM(Y, X_design, family=sm.families.Poisson()).fit()\n",
    "\n",
    "b2, b3 = poisson.params[2], poisson.params[3]\n",
    "mu_oracle = b2 + b3 * X.mean()\n",
    "\n",
    "se_naive = poisson.bse[2]\n",
    "cov = poisson.cov_params()\n",
    "se_delta = np.sqrt(cov[2,2] + X.mean()**2 * cov[3,3] + 2*X.mean()*cov[2,3])\n",
    "\n",
    "oracle_poisson = {\n",
    "    'Oracle (Naive SE)': {\n",
    "        'estimate': mu_oracle,\n",
    "        'se': se_naive,\n",
    "        'ci_lo': mu_oracle - 1.96*se_naive,\n",
    "        'ci_hi': mu_oracle + 1.96*se_naive\n",
    "    },\n",
    "    'Oracle (Delta SE)': {\n",
    "        'estimate': mu_oracle,\n",
    "        'se': se_delta,\n",
    "        'ci_lo': mu_oracle - 1.96*se_delta,\n",
    "        'ci_hi': mu_oracle + 1.96*se_delta\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Oracle Poisson coefficients:\")\n",
    "print(f\"  b2 (T coef) = {b2:.6f}\")\n",
    "print(f\"  b3 (X*T coef) = {b3:.6f}\")\n",
    "print(f\"  mu_oracle = {mu_oracle:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# NN: structural_dml with poisson family\nresult_poisson = structural_dml(\n    Y=Y, T=T, X=X.reshape(-1, 1),\n    family='poisson',\n    n_folds=N_FOLDS,\n    epochs=EPOCHS,\n    # lambda_method='ridge' is default\n    verbose=False\n)\n\nnn_poisson = {\n    'NN (Naive)': {\n        'estimate': result_poisson.mu_naive,\n        'se': result_poisson.theta_hat[:, 1].std() / np.sqrt(N),\n        'ci_lo': result_poisson.mu_naive - 1.96 * result_poisson.theta_hat[:, 1].std() / np.sqrt(N),\n        'ci_hi': result_poisson.mu_naive + 1.96 * result_poisson.theta_hat[:, 1].std() / np.sqrt(N)\n    },\n    'NN (IF Corrected)': {\n        'estimate': result_poisson.mu_hat,\n        'se': result_poisson.se,\n        'ci_lo': result_poisson.ci_lower,\n        'ci_hi': result_poisson.ci_upper\n    }\n}\n\nprint_comparison(oracle_poisson, nn_poisson, MU_TRUE_POISSON, \"POISSON FAMILY RESULTS\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This tutorial demonstrated the `deep_inference` package on 4 model families.\n",
    "\n",
    "**Key findings:**\n",
    "- Oracle (closed-form) estimates provide the benchmark\n",
    "- NN (Naive) estimates may have regularization bias\n",
    "- NN (IF Corrected) estimates should match Oracle performance\n",
    "\n",
    "**The influence function correction:**\n",
    "- Removes regularization bias from neural network estimates\n",
    "- Provides valid standard errors for inference\n",
    "- Enables valid 95% confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY: ALL FAMILIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = [\n",
    "    ('Linear', MU_TRUE_LINEAR, \n",
    "     oracle_linear['Oracle (Delta SE)']['estimate'], \n",
    "     nn_linear['NN (IF Corrected)']['estimate'],\n",
    "     oracle_linear['Oracle (Delta SE)']['ci_lo'] <= MU_TRUE_LINEAR <= oracle_linear['Oracle (Delta SE)']['ci_hi'],\n",
    "     nn_linear['NN (IF Corrected)']['ci_lo'] <= MU_TRUE_LINEAR <= nn_linear['NN (IF Corrected)']['ci_hi']),\n",
    "    \n",
    "    ('Logit', MU_TRUE_LOGIT,\n",
    "     oracle_logit['Oracle (Delta SE)']['estimate'],\n",
    "     nn_logit['NN (IF Corrected)']['estimate'],\n",
    "     oracle_logit['Oracle (Delta SE)']['ci_lo'] <= MU_TRUE_LOGIT <= oracle_logit['Oracle (Delta SE)']['ci_hi'],\n",
    "     nn_logit['NN (IF Corrected)']['ci_lo'] <= MU_TRUE_LOGIT <= nn_logit['NN (IF Corrected)']['ci_hi']),\n",
    "    \n",
    "    ('Gaussian', MU_TRUE_GAUSSIAN,\n",
    "     oracle_gaussian['Oracle (Delta SE)']['estimate'],\n",
    "     nn_gaussian['NN (IF Corrected)']['estimate'],\n",
    "     oracle_gaussian['Oracle (Delta SE)']['ci_lo'] <= MU_TRUE_GAUSSIAN <= oracle_gaussian['Oracle (Delta SE)']['ci_hi'],\n",
    "     nn_gaussian['NN (IF Corrected)']['ci_lo'] <= MU_TRUE_GAUSSIAN <= nn_gaussian['NN (IF Corrected)']['ci_hi']),\n",
    "    \n",
    "    ('Poisson', MU_TRUE_POISSON,\n",
    "     oracle_poisson['Oracle (Delta SE)']['estimate'],\n",
    "     nn_poisson['NN (IF Corrected)']['estimate'],\n",
    "     oracle_poisson['Oracle (Delta SE)']['ci_lo'] <= MU_TRUE_POISSON <= oracle_poisson['Oracle (Delta SE)']['ci_hi'],\n",
    "     nn_poisson['NN (IF Corrected)']['ci_lo'] <= MU_TRUE_POISSON <= nn_poisson['NN (IF Corrected)']['ci_hi']),\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Family':<12} {'True mu*':>10} {'Oracle':>12} {'NN IF':>12} {'Oracle CI':>12} {'NN IF CI':>12}\")\n",
    "print(\"-\" * 80)\n",
    "for family, true, oracle, nn, oracle_cov, nn_cov in summary_data:\n",
    "    print(f\"{family:<12} {true:>10.4f} {oracle:>12.6f} {nn:>12.6f} {'YES' if oracle_cov else 'NO':>12} {'YES' if nn_cov else 'NO':>12}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Tutorial complete!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 5. New `inference()` API\n\nThe new `inference()` API provides additional capabilities beyond `structural_dml()`:\n\n- **Flexible targets**: AME, custom functions with autodiff Jacobians\n- **Randomization mode**: Compute Λ instead of estimating it (faster, more stable)\n- **Regime auto-detection**: Automatically chooses 2-way vs 3-way cross-fitting\n\nLet's demonstrate these features using the same Logit DGP from Section 2.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}